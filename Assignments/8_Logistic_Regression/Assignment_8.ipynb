{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb45c26",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c953621",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, roc_auc_score, classification_report,confusion_matrix,roc_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import streamlit as st\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6f942",
   "metadata": {},
   "source": [
    "## 1. Data Exoploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976baca2",
   "metadata": {},
   "source": [
    "### a. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97897f",
   "metadata": {},
   "source": [
    "### b. Examine features, data types, and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45629f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # No missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2308b7",
   "metadata": {},
   "source": [
    "### c. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebe7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram.\n",
    "df.hist(bins=30, figsize=(12,8))\n",
    "plt.suptitle('Feature Distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot(to check outliers)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e390e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatemap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcff40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot (+ hue on Outcome) ‚Äì quick way to see relationships\n",
    "sns.pairplot(df,\n",
    "             vars=['Glucose','BMI','Age','BloodPressure','Insulin'],\n",
    "             hue='Outcome',\n",
    "             plot_kws={'alpha':0.5},\n",
    "             diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a7351",
   "metadata": {},
   "source": [
    "### Pattern & Correlation Analysis\n",
    "\n",
    "* Glucose and BMI show strong positive correlation with Outcome\n",
    "* Presence of outliers in Insulin and SkinThickness\n",
    "* Target variable: Outcome (0 = Non-diabetic, 1 = Diabetic)\n",
    "* Some features contain 0 values, which are biologically invalid (treated as missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc15b5",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63386b7",
   "metadata": {},
   "source": [
    "### a. Handle missing values\n",
    "Columns where 0 is invalid:\n",
    "* Glucose, BloodPressure, SkinThickness, Insulin, BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)\n",
    "\n",
    "# Median imputation\n",
    "for col in cols_with_zero:\n",
    "    df[col].fillna(df[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b5772",
   "metadata": {},
   "source": [
    "### b. Encode Categorical Variables\n",
    "\n",
    "* The diabetes dataset does not contain any categorical features.\n",
    "All input variables are numerical, and the target variable\n",
    "\"Outcome\" is already binary encoded (0 and 1).\n",
    "\n",
    "* Therefore, no categorical encoding techniques such as\n",
    "Label Encoding or One-Hot Encoding are required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c020e",
   "metadata": {},
   "source": [
    "All features are numeric; the target Outcome is already encoded as 0/1 ‚Äì no further encoding is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1f299",
   "metadata": {},
   "source": [
    "### Feature / Target Split and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a91b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf12c8f",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000) # building the logistic regression model\n",
    "model.fit(X_train_scaled, y_train) # training the model on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7bdae",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871325e",
   "metadata": {},
   "source": [
    "### a. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))\n",
    "print('ROC-AUC:', roc_auc_score(y_test, y_prob))\n",
    "\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923efdca",
   "metadata": {},
   "source": [
    "### b. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38766e74",
   "metadata": {},
   "source": [
    "## 5. Interpretation of Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8268ce6",
   "metadata": {},
   "source": [
    "### a. Coefficient Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d770917",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Coefficient\": model.coef_[0],\n",
    "    \"Odds_Ratio\": np.exp(model.coef_[0])\n",
    "}).sort_values(by=\"Odds_Ratio\", ascending=False)\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf42ea",
   "metadata": {},
   "source": [
    "### b. Significance of Features in Predicting Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d520cd",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "- A positive coefficient indicates that an increase in the feature value increases the likelihood of a patient being diabetic.\n",
    "\n",
    "- A negative coefficient indicates that an increase in the feature value decreases the likelihood of diabetes.\n",
    "\n",
    "- The magnitude of the coefficient reflects the strength of the feature‚Äôs influence on the prediction, assuming all other features remain constant.\n",
    "\n",
    "Since the features were standardized before training, the coefficients can be directly compared to understand relative importance.\n",
    "#### insights:\n",
    "\n",
    " - Glucose - strongest predictor\n",
    "\n",
    " - BMI, Age & Pregnancies - moderate impact\n",
    " \n",
    " Features with smaller or near-zero coefficients contribute less to the prediction and have a weaker relationship with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049519e0",
   "metadata": {},
   "source": [
    "## 6.Streamlit Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faebef4",
   "metadata": {},
   "source": [
    "### a. Save Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f7f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, \"logistic_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564225e",
   "metadata": {},
   "source": [
    "### b. Streamlit App (app.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f97776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load the artefacts you created with train_and_save.py\n",
    "# ------------------------------------------------------------------\n",
    "model   = joblib.load(\"logistic_model.pkl\")   # LogisticRegression\n",
    "scaler  = joblib.load(\"scaler.pkl\")          # StandardScaler\n",
    "# The imputer was saved in the training script; if it is missing we skip it\n",
    "try:\n",
    "    imputer = joblib.load(\"imputer.pkl\")    # SimpleImputer (median)\n",
    "    pipeline = make_pipeline(imputer, scaler, model)\n",
    "except Exception:\n",
    "    pipeline = make_pipeline(scaler, model)   # fallback - no imputation\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2Ô∏è. Feature definition (label,  min, max, step, default, dtype)\n",
    "# ------------------------------------------------------------------\n",
    "FEATURES = [\n",
    "    (\"Pregnancies\",            0,  20, 1,   2,   int),\n",
    "    (\"Glucose\",                0, 200, 1, 120,   int),\n",
    "    (\"BloodPressure\",          0, 150, 1,  70,   int),\n",
    "    (\"SkinThickness\",          0, 100, 1,  20,   int),\n",
    "    (\"Insulin\",                0,1000, 1,  80,   int),\n",
    "    (\"BMI\",                 0.0,  80, 0.1, 30.0, float),\n",
    "    (\"DiabetesPedigreeFunction\",0.0,2.5,0.01,0.5, float),\n",
    "    (\"Age\",                    1, 120, 1,  33,   int),\n",
    "]\n",
    "\n",
    "def get_user_df() -> pd.DataFrame:\n",
    "    \"\"\"Create the eight sidebar number-inputs **once** and return a 1-row DataFrame.\"\"\"\n",
    "    vals = {}\n",
    "    for name, lo, hi, step, default, typ in FEATURES:\n",
    "        if typ is int:\n",
    "            vals[name] = st.sidebar.number_input(\n",
    "                label=name,\n",
    "                min_value=int(lo),\n",
    "                max_value=int(hi),\n",
    "                value=int(default),\n",
    "                step=int(step),\n",
    "                key=name,                 # unique key - prevents duplicate-ID errors\n",
    "                format=\"%d\",\n",
    "            )\n",
    "        else:  # float\n",
    "            vals[name] = st.sidebar.number_input(\n",
    "                label=name,\n",
    "                min_value=float(lo),\n",
    "                max_value=float(hi),\n",
    "                value=float(default),\n",
    "                step=float(step),\n",
    "                key=name,\n",
    "                format=\"%.2f\",\n",
    "            )\n",
    "    return pd.DataFrame([vals])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Streamlit page layout\n",
    "\n",
    "st.set_page_config(page_title=\"Diabetes predictor\", page_icon=\"ü©∫\")\n",
    "st.title(\"ü©∫ Diabetes Prediction - Logistic Regression\")\n",
    "st.write(\n",
    "    \"Enter the eight clinical measurements in the left sidebar, \"\n",
    "    \"press **Predict**, and see the probability of diabetes.\"\n",
    ")\n",
    "\n",
    "# Build the input DataFrame **once**\n",
    "user_df = get_user_df()\n",
    "\n",
    "if st.button(\"üîÆ Predict\"):\n",
    "    prob = pipeline.predict_proba(user_df)[0, 1]      # prob. of class‚ÄØ1 (diabetes)\n",
    "    pred = int(prob >= 0.5)                         # binary decision\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "    col1.metric(\"Probability of Diabetes\", f\"{prob*100:.1f}%\")\n",
    "    col2.metric(\"Predicted class (0 = No, 1 = Yes)\", pred)\n",
    "\n",
    "    if pred:\n",
    "        st.error(\"‚ö†Ô∏è High risk - the model predicts diabetes.\")\n",
    "    else:\n",
    "        st.success(\"‚úÖ Low risk - the model predicts no diabetes.\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4Ô∏è. Show the data that was fed to the model (optional)\n",
    "# ------------------------------------------------------------------\n",
    "with st.expander(\"üîé Input data (what the model sees)\"):\n",
    "    st.dataframe(user_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc589ea",
   "metadata": {},
   "source": [
    "* The Streamlit Application On Diabetes Prediction (app.py) has be created and ready to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbb4bb",
   "metadata": {},
   "source": [
    "### c. Run Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db49da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit run app.py in the terminal to run the app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05840049",
   "metadata": {},
   "source": [
    "### d. Online Deployment (Streamlit Cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebd084",
   "metadata": {},
   "source": [
    "The Logistic Regression model has been deployed using Streamlit Community Cloud by git repo.\n",
    "\n",
    "üîó Live Application Link:  \n",
    "https://diab-pred-model.streamlit.app/\n",
    "\n",
    "The application loads the trained model and scaler, accepts user inputs for all features, and predicts the diabetes outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f960e2",
   "metadata": {},
   "source": [
    "## Interview Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d61a5",
   "metadata": {},
   "source": [
    "#### 1. Difference between Precision and Recall?\n",
    "\n",
    "* Precision: Of all predicted positives, how many are actually positive\n",
    "* Recall: Of all actual positives, how many were correctly predicted\n",
    "\n",
    "Use precision when false positives are costly. Use recall when missing positives is risky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f92007",
   "metadata": {},
   "source": [
    "#### 2. What is Cross-Validation and why is it important?\n",
    "\n",
    "Cross-Validation splits data into multiple folds and trains/tests the model repeatedly to.\n",
    "\n",
    "* Reduces overfitting\n",
    "* Provides a more reliable performance estimate\n",
    "* Ensures model generalizes well to unseen data\n",
    "* Common method: k-fold cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
